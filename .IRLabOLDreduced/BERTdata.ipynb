{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from code_evaluations import define \n",
    "\n",
    "path_to_images = define.imagePath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  von  256\n",
      "26  von  256\n",
      "51  von  256\n",
      "76  von  256\n",
      "101  von  256\n",
      "126  von  256\n",
      "151  von  256\n",
      "176  von  256\n",
      "201  von  256\n",
      "226  von  256\n",
      "251  von  256\n",
      "                      id                                              title\n",
      "0      I000330ba4ea0ad13  Comprehensive Review of Current and Upcoming A...\n",
      "1      I000d8de9c4746ee9      File:DEA Raid protest.jpg - Wikimedia Commons\n",
      "2      I0010d5b5473065fa  Vector Medical Poster Obesity. Reasons Of The ...\n",
      "3      I001652ec040f07c4        Your Guide to LGBTQIAPK Addiction Treatment\n",
      "4      I001a318b3176d501  i get paid below minimum wage after taxes : memes\n",
      "...                  ...                                                ...\n",
      "23836  Ifff6a608e404c89b  Phelps doubts doping protests will bring real ...\n",
      "23837  Ifff77669db5d587b  Global 5G Protest Day - Life-Environmental Net...\n",
      "23838  Ifff91dfb5b0256e8              Fixing Canadas Unfixed Election Dates\n",
      "23839  Ifffa6ec57e1f11e1  The Euthanasia Coaster by recyclebin - Meme Ce...\n",
      "23840  Iffff8be6926a808e  Public Opinion on the Death Penalty  Pew Resea...\n",
      "\n",
      "[23841 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os.path\n",
    "import re, string\n",
    "\n",
    "data_dir = path_to_images + '/images/'\n",
    "\n",
    "dataList = []\n",
    "image_files = [f for f in os.listdir(data_dir)]\n",
    "for f in image_files:\n",
    "    #print(f)\n",
    "    subdir = data_dir + f\n",
    "    subdir_files = [f for f in os.listdir(subdir)]\n",
    "    if (image_files.index(f) % 25 == 0):\n",
    "        print(image_files.index(f) + 1, \" von \", len(image_files))\n",
    "\n",
    "    for f2 in subdir_files:\n",
    "        #print(f2)\n",
    "        subsubdir = subdir + \"/\" + f2 + \"/pages/\"\n",
    "        dir = data_dir + f + \"/\" + f2 + \"/pages/\" + \\\n",
    "            os.listdir(subsubdir)[0] + \"/snapshot/dom.html\"\n",
    "        if not (os.path.isfile(dir)): continue\n",
    "        # print(dir)\n",
    "        ### Opens html file\n",
    "        html = open(dir, encoding=\"utf-8\")\n",
    "        ### Cleans html file\n",
    "        soup = BeautifulSoup(html)\n",
    "\n",
    "        id = dir[-59:-42]\n",
    "        if not bool(soup.title): \n",
    "            title = \"missing title field\"\n",
    "        elif not bool(soup.title.string):\n",
    "            title = \"empty title field\"\n",
    "        else: \n",
    "            title = soup.title.string\n",
    "            title = re.sub('[^a-zA-Z0-9\\.\\:\\,\\;\\-\\!\\?\\ ]+', '', title)\n",
    "        # print(title)\n",
    "        dataList.append([id, title])\n",
    "    #     break\n",
    "    # break\n",
    "# print(dataList)\n",
    "df = pd.DataFrame(dataList, columns = [\"id\", \"title\"])\n",
    "print(df)\n",
    "df.to_csv('htmlTitlesNEW.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "options.add_argument(\"--window-size=1920,1200\")\n",
    "driver = webdriver.Chrome(options=options, executable_path=r'C:/Users/thilo/OneDrive/Dokumente/Universit√§tLeipzig/DataScience3/InformationRetrieval/irlab/data/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ids_con = ['If66787cad4a7f247', 'I5267c4a222aad283','I5ad3b457d1b923b1', 'I2db1aa14b7807aed', 'I2b91de90a27d0506', 'I2090f7e152b056ed', 'I1106058d9d4025c9', 'I046ddd15dc82845a', 'I8ccb8618e57ceaec', 'Icc511540b95aee35']\n",
    "result_ids_pro = ['I680736496d979c9e', 'I74c480d452e7787c', 'I904a6b8f9f436788', 'I0bba050b1349e96e', 'I6982d2a3cfce7e41', 'I963f4855e811efcd', 'I1dfcdb482b33207a', 'I5a9ecd0b71dd3960', 'I26e599e89ba6bf98', 'I2d9b1996f5c349f7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dictionary with all topics\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('topics.xml')\n",
    "topics = tree.findall('topic')\n",
    "\n",
    "topicsDic = {}\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find('title').text\n",
    "    number = topic.find('number').text\n",
    "    topicsDic[number] = title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "data_dir = path_to_images + '/images/'\n",
    "image_files = [f for f in os.listdir(data_dir)]\n",
    "for f in image_files:\n",
    "    subdir = data_dir + f\n",
    "    subdir_files = [f for f in os.listdir(subdir)]\n",
    "    #print(\"\\n\", f)\n",
    "\n",
    "    for f2 in subdir_files:\n",
    "        print(\"   \", subdir_files.index(f2), \" von \", len(subdir_files))\n",
    "        subsubdir = subdir + \"/\" + f2 + \"/pages/\"\n",
    "        subsubdir_files = [f for f in os.listdir(subsubdir)]\n",
    "        #print(\"\\n\", f2)\n",
    "\n",
    "        for f3 in subsubdir_files:\n",
    "            with open(subsubdir + f3 + \"/page-url.txt\") as f:\n",
    "                this_link = f.read()\n",
    "                driver.get(this_link)\n",
    "                try:\n",
    "                    elem = driver.find_element(By.XPATH, \"/html/body\")\n",
    "                except:\n",
    "                    elem = driver.find_element(By.XPATH, \"/html\")\n",
    "                \n",
    "            inner = elem.text\n",
    "            #print(inner)\n",
    "            try:\n",
    "                with open(subsubdir + \"/\" + f3 + '/snapshot/HTMLbody.txt', 'w') as s:\n",
    "                    s.write(inner)\n",
    "            except:\n",
    "                print(\"Error saving\")\n",
    "                #data_list.append(f2 + '\\t' + inner)\n",
    "\n",
    "    #         # save doc to txt-file\n",
    "    #         filename = os.path.join(subsubsubdir + \"text_pp.txt\"  )\n",
    "    #         print(filename)\n",
    "    #         f = open(filename, \"w\")\n",
    "    #         f.write(doc)\n",
    "    #         f.close()   \n",
    "            if(subdir_files.index(f2) == 3):\n",
    "                break\n",
    "    break\n",
    "#print(data_list)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3898892d7e34557bb8499aff9aa0ccd3bf7bab375649613f01d0952879e4c360"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
