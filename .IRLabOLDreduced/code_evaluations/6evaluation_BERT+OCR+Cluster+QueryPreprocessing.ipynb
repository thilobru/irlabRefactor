{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_name = \"6evaluation_topics\"\n",
    "tsv_name = \"6evaluation_stance_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import define\n",
    "import json\n",
    "from os import listdir\n",
    "import csv\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "import IPython\n",
    "es = Elasticsearch(HOST=\"http://localhost\", PORT=9200)\n",
    "es = Elasticsearch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'Should teachers get tenure?',\n",
       " '2': 'Is vaping with e-cigarettes safe?',\n",
       " '3': 'Should insider trading be allowed?',\n",
       " '4': 'Should corporal punishment be used in schools?',\n",
       " '5': 'Should social security be privatized?',\n",
       " '6': 'Is a college education worth it?',\n",
       " '7': 'Should felons who have completed their sentence be allowed to vote?',\n",
       " '8': 'Should abortion be legal?',\n",
       " '9': 'Should students have to wear school uniforms?',\n",
       " '10': 'Should any vaccines be required for children?',\n",
       " '11': 'Should performance-enhancing drugs be accepted in sports?',\n",
       " '12': 'Should birth control pills be available over the counter?',\n",
       " '13': 'Can alternative energy effectively replace fossil fuels?',\n",
       " '14': 'Is sexual orientation determined at birth?',\n",
       " '15': 'Should animals be used for scientific or commercial testing?',\n",
       " '16': 'Should prescription drugs be advertised directly to consumers?',\n",
       " '17': 'Should recreational marijuana be legal?',\n",
       " '18': 'Should churches remain tax-exempt?',\n",
       " '19': 'Should gay marriage be legal?',\n",
       " '20': 'Is drinking milk healthy for humans?',\n",
       " '21': 'Is human activity primarily responsible for global climate change?',\n",
       " '22': 'Is a two-state solution an acceptable solution to the Israeli-Palestinian conflict?',\n",
       " '23': 'Should euthanasia or physician-assisted suicide be legal?',\n",
       " '24': 'Does lowering the federal corporate income tax rate create jobs?',\n",
       " '26': 'Do standardized tests improve education?',\n",
       " '27': 'Should more gun control laws be enacted?',\n",
       " '28': 'Should prostitution be legal?',\n",
       " '29': 'Should the government allow illegal immigrants to become citizens?',\n",
       " '30': 'Should adults have the right to carry a concealed handgun?',\n",
       " '31': 'Is obesity a disease?',\n",
       " '32': 'Do electronic voting machines improve the voting process?',\n",
       " '33': 'Should people become vegetarian?',\n",
       " '34': 'Are social networking sites good for our society?',\n",
       " '35': 'Do violent video games contribute to youth violence?',\n",
       " '36': 'Is golf a sport?',\n",
       " '37': 'Is cell phone radiation safe?',\n",
       " '38': 'Should marijuana be a medical option?',\n",
       " '39': 'Should the federal minimum wage be increased?',\n",
       " '40': 'Should the death penalty be allowed?',\n",
       " '41': 'Should student loan debt be easier to discharge in bankruptcy?',\n",
       " '42': 'Should fighting be allowed in hockey?',\n",
       " '43': 'Should bottled water be banned?',\n",
       " '44': 'Should election day be a national holiday?',\n",
       " '45': 'Should the penny stay in circulation?',\n",
       " '46': 'Should net neutrality be restored?',\n",
       " '47': 'Is homework beneficial?',\n",
       " '48': 'Should the voting age be lowered?',\n",
       " '49': 'Should body cameras be mandatory for police?',\n",
       " '50': 'Should everyone get a universal basic income?'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make dictionary with all topics\n",
    "import xml.etree.ElementTree as ET\n",
    "# tree = ET.parse('topics_selected.xml')\n",
    "tree = ET.parse('topics.xml')\n",
    "topics = tree.findall('topic')\n",
    "\n",
    "topicsDic = {}\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find('title').text\n",
    "    number = topic.find('number').text\n",
    "    topicsDic[number] = title\n",
    "\n",
    "topicsDic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### query preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thilo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_preprocessing(query):\n",
    "    stopwords = {'should', 'get', 'is', 'with', 'be', 'used', 'in', 'a', 'it', 'who', 'have', 'to', 'for', 'the', 'can', 'at', 'or', 'an',  'does', 'do', 'are', 'our'}\n",
    "    query = query.replace(\"?\", \"\")\n",
    "\n",
    "    rslt_query = ''\n",
    "    for word in query.split():\n",
    "      if word.lower() not in stopwords:\n",
    "        word = lemmatizer.lemmatize(word)\n",
    "        rslt_query += word + ' '\n",
    "    #print(query + ': ' + rslt_query)\n",
    "\n",
    "    return rslt_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the search for the BERT sentiment with ocr and imgae clustering combined\n",
    "def search_BERT_OCR_Clustering(query, num_results):\n",
    "    body_positive = {\n",
    "        \"from\":0,\n",
    "        \"size\":num_results,\n",
    "        \"query\": {\n",
    "        \"function_score\": {\n",
    "        \"query\": {\n",
    "            \"bool\":{\n",
    "                \"should\":[\n",
    "                    {\"match\": { \"document_text\":{\"query\":query}}},\n",
    "                    {\"match\": {\"ocr_text\":{\"query\":query, \"boost\":5}}}\n",
    "                ],\n",
    "\n",
    "                \"filter\":[\n",
    "                    {\"match\": {\"sentiment_html_title\": {\"query\": \"Positive\"}}}\n",
    "                ]\n",
    "            }   \n",
    "        },\n",
    "        #\"boost\": \"5\", \n",
    "        \"functions\": [\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"0\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"1\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"2\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"3\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"4\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"5\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"6\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"7\" } },\"weight\": 2.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"8\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"9\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"10\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"11\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"12\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"13\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"999\" } },\"weight\": 0.0}\n",
    "        ],      \n",
    "        \"max_boost\": 5.0,\n",
    "        \"score_mode\": \"max\",\n",
    "        \"boost_mode\": \"multiply\",\n",
    "        \"min_score\": 0.0\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    res_positive = es.search(index=\"boromir_index_dif_clust_meth\", body=body_positive)\n",
    "\n",
    "    body_negative = {\n",
    "        \"from\":0,\n",
    "        \"size\":num_results,\n",
    "        \"query\": {\n",
    "        \"function_score\": {\n",
    "        \"query\": {\n",
    "            \"bool\":{\n",
    "                \"should\":[\n",
    "                    {\"match\": { \"document_text\":{\"query\":query}}},\n",
    "                    {\"match\": {\"ocr_text\":{\"query\":query, \"boost\":5}}}\n",
    "                ],\n",
    "\n",
    "                \"filter\":[\n",
    "                    {\"match\": {\"sentiment_html_title\": {\"query\": \"Negative\"}}}\n",
    "                ]\n",
    "            }   \n",
    "        },\n",
    "        #\"boost\": \"5\", \n",
    "        \"functions\": [\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"0\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"1\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"2\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"3\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"4\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"5\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"6\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"7\" } },\"weight\": 2.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"8\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"9\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"10\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"11\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"12\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"13\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"999\" } },\"weight\": 0.0}\n",
    "        ],      \n",
    "        \"max_boost\": 5.0,\n",
    "        \"score_mode\": \"max\",\n",
    "        \"boost_mode\": \"multiply\",\n",
    "        \"min_score\": 0.0\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    res_negative = es.search(index=\"boromir_index_dif_clust_meth\", body=body_negative)\n",
    "\n",
    "    # get ID's from retrieved documents\n",
    "    result_positive_ids = []\n",
    "    results_positive = res_positive.get('hits').get('hits')\n",
    "\n",
    "    for doc in results_positive:\n",
    "        id = doc.get('_id')\n",
    "        result_positive_ids.append(id)\n",
    "\n",
    "    result_negative_ids = []\n",
    "    results_negative = res_negative.get('hits').get('hits')\n",
    "\n",
    "    for doc in results_negative:\n",
    "        id = doc.get('_id')\n",
    "        result_negative_ids.append(id)\n",
    "\n",
    "    return result_positive_ids, result_negative_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-e5c07691fc57>:45: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  res_positive = es.search(index=\"boromir_index_dif_clust_meth\", body=body_positive)\n",
      "C:\\Users\\miria\\anaconda3\\lib\\site-packages\\elasticsearch\\connection\\base.py:209: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n",
      "<ipython-input-7-e5c07691fc57>:89: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  res_negative = es.search(index=\"boromir_index_dif_clust_meth\", body=body_negative)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should teachers get tenure? :  teacher tenure  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  428\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  9 / 10\n",
      "Precision (Con):  0.9\n",
      "Total Rank for Query (Con):  298 \n",
      "\n",
      "Is vaping with e-cigarettes safe? :  vaping e-cigarettes safe  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  437\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  10 / 10\n",
      "Precision (Con):  1.0\n",
      "Total Rank for Query (Con):  507 \n",
      "\n",
      "Should insider trading be allowed? :  insider trading allowed  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  535\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  3 / 10\n",
      "Precision (Con):  0.3\n",
      "Total Rank for Query (Con):  150 \n",
      "\n",
      "Should corporal punishment be used in schools? :  corporal punishment school  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  692\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  7 / 10\n",
      "Precision (Con):  0.7\n",
      "Total Rank for Query (Con):  253 \n",
      "\n",
      "Should social security be privatized? :  social security privatized  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  585\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  7 / 10\n",
      "Precision (Con):  0.7\n",
      "Total Rank for Query (Con):  220 \n",
      "\n",
      "Is a college education worth it? :  college education worth  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  9 / 10\n",
      "Precision (Pro):  0.9\n",
      "Total Rank for Query (Pro):  465\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  9 / 10\n",
      "Precision (Con):  0.9\n",
      "Total Rank for Query (Con):  548 \n",
      "\n",
      "Should felons who have completed their sentence be allowed to vote? :  felon completed their sentence allowed vote  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  407\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  8 / 10\n",
      "Precision (Con):  0.8\n",
      "Total Rank for Query (Con):  102 \n",
      "\n",
      "Should abortion be legal? :  abortion legal  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  332\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  9 / 10\n",
      "Precision (Con):  0.9\n",
      "Total Rank for Query (Con):  481 \n",
      "\n",
      "Should students have to wear school uniforms? :  student wear school uniform  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  375\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  131 \n",
      "\n",
      "Should any vaccines be required for children? :  any vaccine required child  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  9 / 10\n",
      "Precision (Pro):  0.9\n",
      "Total Rank for Query (Pro):  445\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  6 / 10\n",
      "Precision (Con):  0.6\n",
      "Total Rank for Query (Con):  368 \n",
      "\n",
      "Should performance-enhancing drugs be accepted in sports? :  performance-enhancing drug accepted sport  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  590\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  3 / 10\n",
      "Precision (Con):  0.3\n",
      "Total Rank for Query (Con):  162 \n",
      "\n",
      "Should birth control pills be available over the counter? :  birth control pill available over counter  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  465\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  10 / 10\n",
      "Precision (Con):  1.0\n",
      "Total Rank for Query (Con):  575 \n",
      "\n",
      "Can alternative energy effectively replace fossil fuels? :  alternative energy effectively replace fossil fuel  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  315\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  268 \n",
      "\n",
      "Is sexual orientation determined at birth? :  sexual orientation determined birth  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  410\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  203 \n",
      "\n",
      "Should animals be used for scientific or commercial testing? :  animal scientific commercial testing  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  562\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  10 / 10\n",
      "Precision (Con):  1.0\n",
      "Total Rank for Query (Con):  446 \n",
      "\n",
      "Should prescription drugs be advertised directly to consumers? :  prescription drug advertised directly consumer  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  9 / 10\n",
      "Precision (Pro):  0.9\n",
      "Total Rank for Query (Pro):  567\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  9 / 10\n",
      "Precision (Con):  0.9\n",
      "Total Rank for Query (Con):  457 \n",
      "\n",
      "Should recreational marijuana be legal? :  recreational marijuana legal  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  636\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  3 / 10\n",
      "Precision (Con):  0.3\n",
      "Total Rank for Query (Con):  174 \n",
      "\n",
      "Should churches remain tax-exempt? :  church remain tax-exempt  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  9 / 10\n",
      "Precision (Pro):  0.9\n",
      "Total Rank for Query (Pro):  407\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  10 / 10\n",
      "Precision (Con):  1.0\n",
      "Total Rank for Query (Con):  402 \n",
      "\n",
      "Should gay marriage be legal? :  gay marriage legal  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  519\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  5 / 10\n",
      "Precision (Con):  0.5\n",
      "Total Rank for Query (Con):  240 \n",
      "\n",
      "Is drinking milk healthy for humans? :  drinking milk healthy human  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  303\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  191 \n",
      "\n",
      "Is human activity primarily responsible for global climate change? :  human activity primarily responsible global climate change  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  426\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  7 / 10\n",
      "Precision (Con):  0.7\n",
      "Total Rank for Query (Con):  310 \n",
      "\n",
      "Is a two-state solution an acceptable solution to the Israeli-Palestinian conflict? :  two-state solution acceptable solution Israeli-Palestinian conflict  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  530\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  287 \n",
      "\n",
      "Should euthanasia or physician-assisted suicide be legal? :  euthanasia physician-assisted suicide legal  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  460\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  9 / 10\n",
      "Precision (Con):  0.9\n",
      "Total Rank for Query (Con):  406 \n",
      "\n",
      "Does lowering the federal corporate income tax rate create jobs? :  lowering federal corporate income tax rate create job  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  387\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  3 / 10\n",
      "Precision (Con):  0.3\n",
      "Total Rank for Query (Con):  255 \n",
      "\n",
      "Do standardized tests improve education? :  standardized test improve education  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  350\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  9 / 10\n",
      "Precision (Con):  0.9\n",
      "Total Rank for Query (Con):  373 \n",
      "\n",
      "Should more gun control laws be enacted? :  more gun control law enacted  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  444\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  8 / 10\n",
      "Precision (Con):  0.8\n",
      "Total Rank for Query (Con):  360 \n",
      "\n",
      "Should prostitution be legal? :  prostitution legal  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  403\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  7 / 10\n",
      "Precision (Con):  0.7\n",
      "Total Rank for Query (Con):  444 \n",
      "\n",
      "Should the government allow illegal immigrants to become citizens? :  government allow illegal immigrant become citizen  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  9 / 10\n",
      "Precision (Pro):  0.9\n",
      "Total Rank for Query (Pro):  565\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  5 / 10\n",
      "Precision (Con):  0.5\n",
      "Total Rank for Query (Con):  214 \n",
      "\n",
      "Should adults have the right to carry a concealed handgun? :  adult right carry concealed handgun  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  349\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  239 \n",
      "\n",
      "Is obesity a disease? :  obesity disease  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  620\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  6 / 10\n",
      "Precision (Con):  0.6\n",
      "Total Rank for Query (Con):  247 \n",
      "\n",
      "Do electronic voting machines improve the voting process? :  electronic voting machine improve voting process  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  417\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  7 / 10\n",
      "Precision (Con):  0.7\n",
      "Total Rank for Query (Con):  432 \n",
      "\n",
      "Should people become vegetarian? :  people become vegetarian  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  9 / 10\n",
      "Precision (Pro):  0.9\n",
      "Total Rank for Query (Pro):  336\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  3 / 10\n",
      "Precision (Con):  0.3\n",
      "Total Rank for Query (Con):  124 \n",
      "\n",
      "Are social networking sites good for our society? :  social networking site good society  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  321\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  6 / 10\n",
      "Precision (Con):  0.6\n",
      "Total Rank for Query (Con):  320 \n",
      "\n",
      "Do violent video games contribute to youth violence? :  violent video game contribute youth violence  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  469\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  7 / 10\n",
      "Precision (Con):  0.7\n",
      "Total Rank for Query (Con):  372 \n",
      "\n",
      "Is golf a sport? :  golf sport  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  6 / 10\n",
      "Precision (Pro):  0.6\n",
      "Total Rank for Query (Pro):  406\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  186 \n",
      "\n",
      "Is cell phone radiation safe? :  cell phone radiation safe  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  526\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  10 / 10\n",
      "Precision (Con):  1.0\n",
      "Total Rank for Query (Con):  400 \n",
      "\n",
      "Should marijuana be a medical option? :  marijuana medical option  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  5 / 10\n",
      "Precision (Pro):  0.5\n",
      "Total Rank for Query (Pro):  289\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  5 / 10\n",
      "Precision (Con):  0.5\n",
      "Total Rank for Query (Con):  252 \n",
      "\n",
      "Should the federal minimum wage be increased? :  federal minimum wage increased  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  647\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  10 / 10\n",
      "Precision (Con):  1.0\n",
      "Total Rank for Query (Con):  235 \n",
      "\n",
      "Should the death penalty be allowed? :  death penalty allowed  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  416\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  8 / 10\n",
      "Precision (Con):  0.8\n",
      "Total Rank for Query (Con):  410 \n",
      "\n",
      "Should student loan debt be easier to discharge in bankruptcy? :  student loan debt easier discharge bankruptcy  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  632\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  10 / 10\n",
      "Precision (Con):  1.0\n",
      "Total Rank for Query (Con):  371 \n",
      "\n",
      "Should fighting be allowed in hockey? :  fighting allowed hockey  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  549\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  3 / 10\n",
      "Precision (Con):  0.3\n",
      "Total Rank for Query (Con):  100 \n",
      "\n",
      "Should bottled water be banned? :  bottled water banned  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  531\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  7 / 10\n",
      "Precision (Con):  0.7\n",
      "Total Rank for Query (Con):  337 \n",
      "\n",
      "Should election day be a national holiday? :  election day national holiday  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  443\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  3 / 10\n",
      "Precision (Con):  0.3\n",
      "Total Rank for Query (Con):  101 \n",
      "\n",
      "Should the penny stay in circulation? :  penny stay circulation  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  559\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  5 / 10\n",
      "Precision (Con):  0.5\n",
      "Total Rank for Query (Con):  374 \n",
      "\n",
      "Should net neutrality be restored? :  net neutrality restored  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  376\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  9 / 10\n",
      "Precision (Con):  0.9\n",
      "Total Rank for Query (Con):  482 \n",
      "\n",
      "Is homework beneficial? :  homework beneficial  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  410\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  10 / 10\n",
      "Precision (Con):  1.0\n",
      "Total Rank for Query (Con):  474 \n",
      "\n",
      "Should the voting age be lowered? :  voting age lowered  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  9 / 10\n",
      "Precision (Pro):  0.9\n",
      "Total Rank for Query (Pro):  500\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  160 \n",
      "\n",
      "Should body cameras be mandatory for police? :  body camera mandatory police  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  410\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  4 / 10\n",
      "Precision (Con):  0.4\n",
      "Total Rank for Query (Con):  153 \n",
      "\n",
      "Should everyone get a universal basic income? :  everyone universal basic income  \n",
      "======================================\n",
      "Number of pictures that fit to the query (Pro):  10 / 10\n",
      "Precision (Pro):  1.0\n",
      "Total Rank for Query (Pro):  499\n",
      "....................................\n",
      "Number of pictures that fit to the query (Con):  7 / 10\n",
      "Precision (Con):  0.7\n",
      "Total Rank for Query (Con):  408 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_ranks_pro = []\n",
    "all_ranks_con = []\n",
    "numbers = []\n",
    "true_pos_pro = []\n",
    "true_pos_con = []\n",
    "avg_rank_pro = []\n",
    "avg_rank_con = []\n",
    "\n",
    "num_results = 10 # number of result id's we want to get\n",
    "\n",
    "for topic in topicsDic:\n",
    "    pre_query = topicsDic.get(topic)\n",
    "    query = query_preprocessing(pre_query)\n",
    "    result_ids_pro, result_ids_con = search_BERT_OCR_Clustering(query, num_results)\n",
    "\n",
    "    print(pre_query, \": \", query, \"\\n======================================\")\n",
    "\n",
    "    TP_pro = 0\n",
    "    TP_con = 0\n",
    "    total_rank_pro = 0 # the smaller the better\n",
    "    total_rank_con = 0 # the smaller the better\n",
    "\n",
    "    # check each result id if it fits the topic (pro)\n",
    "    for id in result_ids_pro:\n",
    "\n",
    "        path = define.imagePath() + \"/images/\"  + id[0:3] + \"/\" + id + \"/pages/\"\n",
    "        file = listdir(path)\n",
    "        path = path +  file[0] + \"/rankings.jsonl\"\n",
    "\n",
    "        lines = []\n",
    "        for line in open(path, 'r'):\n",
    "            lines.append(json.loads(line))\n",
    "\n",
    "        # print(lines[0]['query'])\n",
    "\n",
    "        if lines[0]['topic'] == topic:\n",
    "            TP_pro += 1\n",
    "            rank = lines[0]['rank']\n",
    "            total_rank_pro += rank\n",
    "\n",
    "    # check each result id if it fits the topic (con)\n",
    "    for id in result_ids_con:\n",
    "\n",
    "        path = define.imagePath() + \"/images/\"  + id[0:3] + \"/\" + id + \"/pages/\"\n",
    "        file = listdir(path)\n",
    "        path = path +  file[0] + \"/rankings.jsonl\"\n",
    "\n",
    "        lines = []\n",
    "        for line in open(path, 'r'):\n",
    "            lines.append(json.loads(line))\n",
    "\n",
    "        # print(lines[0]['query'])\n",
    "\n",
    "        if lines[0]['topic'] == topic:\n",
    "            TP_con += 1\n",
    "            rank = lines[0]['rank']\n",
    "            total_rank_con += rank\n",
    "    \n",
    "    # print search performance for this topic\n",
    "        \n",
    "    print(\"Number of pictures that fit to the query (Pro): \", TP_pro, \"/\", num_results)\n",
    "    print(\"Precision (Pro): \", TP_pro/num_results)\n",
    "    print(\"Total Rank for Query (Pro): \", total_rank_pro)\n",
    "    print(\"....................................\")\n",
    "    print(\"Number of pictures that fit to the query (Con): \", TP_con, \"/\", num_results)\n",
    "    print(\"Precision (Con): \", TP_con/num_results)\n",
    "    print(\"Total Rank for Query (Con): \", total_rank_con, \"\\n\")\n",
    "\n",
    "    all_ranks_pro.append(total_rank_pro)\n",
    "    all_ranks_con.append(total_rank_con)\n",
    "    numbers.append(topic)\n",
    "    true_pos_pro.append(TP_pro)\n",
    "    true_pos_con.append(TP_con)\n",
    "    avg_rank_pro.append(round(total_rank_pro/TP_pro, 2))\n",
    "    avg_rank_con.append(round(total_rank_con/TP_con, 2))\n",
    "\n",
    "# make final dataframe\n",
    "df = pd.DataFrame({'Topic': numbers, 'Rank Pro' : all_ranks_pro,  'TP Pro' : true_pos_pro, 'AVG_Rank Pro' : avg_rank_pro, 'Rank Con' : all_ranks_con, 'TP Con' : true_pos_con, 'AVG_Rank Con' : avg_rank_con})\n",
    "df.to_csv('../'+notebook_name+'.tsv', index = False, sep='\\t', line_terminator = '\\r\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import define\n",
    "\n",
    "path_to_images = define.imagePath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resultHTML = notebook_name+'.html'\n",
    "\n",
    "htmlEval = '<!DOCTYPE html> <html>     <head>         <meta charset=\"UTF-8\" name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\">         <title>Evaluation</title> <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\">   <link rel=\"stylesheet\" href=\"myCss.css\">      <script src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\" integrity=\"sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN\" crossorigin=\"anonymous\"></script>   <script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js\" integrity=\"sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q\" crossorigin=\"anonymous\"></script>    <script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js\" integrity=\"sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl\" crossorigin=\"anonymous\"></script> '\n",
    "htmlEval = htmlEval + '<script language=\"Javascript\" > \\n const dataList = [] \\n function addDataToList(query, argpro, argcon, pos, neg) {  var { value } = document.getElementById(\"user_name\").elements[\"user\"]   \\n  if(value == \"\"){ alert (\"Please fill in User!\")} \\n  else{ \\n dataList.push(query)    \\n var { value } = argpro     \\n dataList.push(value)    \\n var { value } = argcon     \\n dataList.push(value)     \\n var { value } = pos   \\n dataList.push(value)     \\n var { value } = neg  \\n dataList.push(value)    \\n  var { value } = document.getElementById(\"user_name\").elements[\"user\"]   \\n  dataList.push(value)       \\n dataList.push(\" \\\\n\") \\n alert(\"Inhalt von dataList: \"+dataList)  } }  \\n function downloadFile() { \\n const textFile = btoa(\"query \\\\t Argumentative images pro \\\\t Argumentative images con \\\\t correct positives \\\\t correct negatives \\\\t user_name \\\\n \\\\t\" + dataList.join(\"\\\\t\")) \\n const saveElement = document.createElement(\"a\") \\n saveElement.href = `data:text/plain;base64,${textFile}` \\n var { value } = document.getElementById(\"user_name\").elements[\"user\"]   \\n  saveElement.download = \"' + tsv_name + '\"+value+\".tsv\" \\n document.body.appendChild(saveElement) \\n saveElement.click() \\n document.body.removeChild(saveElement)  } \\n </script>'\n",
    "htmlEval = htmlEval + '</head> <body>   \\n  <div class=\"form-group mb-5\">   \\n  <input id=\"download_btn\" type=\"submit\" class=\"btn btn-primary\" onClick=\"downloadFile(); \" value=\"Exportieren\" />    \\n  </div>  \\n  <div class=\"container-out\"> \\n  <form name=\"username\" action=\"\" method=\"post\" id=\"user_name\">   \\n  <div class=\"form-group row\">    \\n  <label for=\"username\" class=\"col-sm-2 col-form-label\">User: </label>    \\n  <div class=\"col-sm-10\"> \\n  <select multiple class=\"form-control\" name=\"user\">  \\n  <option>Gregor</option> \\n  <option>Miriam</option> \\n  <option>Shirin</option> \\n  <option>Thilo</option>  \\n  </select></div> \\n  </div>  \\n  </form>'\n",
    "num_results = 10\n",
    "\n",
    "\n",
    "queryListdf = pd.DataFrame(columns = ['topic', 'stance', 'id'])\n",
    "for tid in topicsDic:\n",
    "    pre_query = topicsDic.get(tid)\n",
    "    query = query_preprocessing(pre_query)\n",
    "\n",
    "    result_ids_pro, result_ids_con =  search_BERT_OCR_Clustering(query, num_results)\n",
    "    src_pro = []\n",
    "    src_con = []\n",
    "\n",
    "    for ids in result_ids_pro:\n",
    "        src_pro.append(\"images/\"  + ids[0:3] + \"/\" + ids + \"/image.png\")\n",
    "    for ids in result_ids_con:\n",
    "        src_con.append(\"images/\"  + ids[0:3] + \"/\" + ids + \"/image.png\")\n",
    "\n",
    "    link_pro = []\n",
    "    link_con = []\n",
    "    #open only directory to get link\n",
    "    for ids in result_ids_pro:\n",
    "        with open(path_to_images + \"/images/\" + ids[0:3] + \"/\" + ids + \"/pages/\" + listdir(path_to_images + \"/images/\" + ids[0:3] + \"/\" + ids + \"/pages\")[0] + \"/page-url.txt\") as f:\n",
    "            this_link = f.read()\n",
    "            link_pro.append(this_link)\n",
    "\n",
    "    for ids in result_ids_con:\n",
    "        with open(path_to_images + \"/images/\" + ids[0:3] + \"/\" + ids + \"/pages/\" + listdir(path_to_images + \"/images/\" + ids[0:3] + \"/\" + ids + \"/pages\")[0] + \"/page-url.txt\") as f:\n",
    "            this_link = f.read()\n",
    "            link_con.append(this_link)\n",
    "\n",
    "    #data for HTML processing\n",
    "    # queryList.append(query)\n",
    "    evaluation = open(\"evaluation+link.html\").read().format(query=pre_query, \n",
    "                                    firstpro = src_pro[0],\n",
    "                                    secondpro = src_pro[1],\n",
    "                                    thirdpro = src_pro[2],\n",
    "                                    fourthpro = src_pro[3],\n",
    "                                    fifthpro = src_pro[4],\n",
    "                                    sixthpro = src_pro[5], \n",
    "                                    seventhpro = src_pro[6], \n",
    "                                    eighthpro = src_pro[7], \n",
    "                                    ninthpro = src_pro[8], \n",
    "                                    tenthpro = src_pro[9], \n",
    "                                    firstcon = src_con[0], \n",
    "                                    secondcon = src_con[1], \n",
    "                                    thirdcon = src_con[2], \n",
    "                                    fourthcon = src_con[3], \n",
    "                                    fifthcon = src_con[4], \n",
    "                                    sixthcon = src_con[5],\n",
    "                                    seventhcon = src_con[6],\n",
    "                                    eighthcon = src_con[7], \n",
    "                                    ninthcon = src_con[8], \n",
    "                                    tenthcon = src_con[9], \n",
    "                                    onepro = link_pro[0], \n",
    "                                    twopro = link_pro[1], \n",
    "                                    threepro = link_pro[2], \n",
    "                                    fourpro = link_pro[3], \n",
    "                                    fivepro = link_pro[4], \n",
    "                                    sixpro = link_pro[5], \n",
    "                                    sevenpro = link_pro[6], \n",
    "                                    eightpro = link_pro[7], \n",
    "                                    ninepro = link_pro[8], \n",
    "                                    tenpro = link_pro[9],\n",
    "                                    onecon = link_con[0],\n",
    "                                    twocon = link_con[1], \n",
    "                                    threecon = link_con[2], \n",
    "                                    fourcon = link_con[3], \n",
    "                                    fivecon = link_con[4], \n",
    "                                    sixcon = link_con[5], \n",
    "                                    sevencon = link_con[6], \n",
    "                                    eightcon = link_con[7], \n",
    "                                    ninecon = link_con[8], \n",
    "                                    tencon = link_con[9])\n",
    "    #print(topic)\n",
    "    # for id in result_ids_pro:\n",
    "    #     # print(id)\n",
    "    #     queryListdf = queryListdf.append({\"topic\": query, \"stance\": \"pro\", \"id\": (\"/images/\"  + id[0:3] + \"/\" + id + \"/pages/\")}, ignore_index=True)\n",
    "    # for id in result_ids_con:\n",
    "    #     queryListdf = queryListdf.append({\"topic\": query, \"stance\": \"con\", \"id\": (\"/images/\"  + id[0:3] + \"/\" + id + \"/pages/\")}, ignore_index=True)\n",
    "\n",
    "    htmlEval = htmlEval + evaluation\n",
    "\n",
    "    \n",
    "htmlEval = htmlEval + '</body> </html>'\n",
    "file = open(resultHTML, 'w')\n",
    "file.write(htmlEval)\n",
    "file.close()\n",
    "    \n",
    "##debugging/check\n",
    "#print(queryListdf)\n",
    "#queryListdf.to_csv(\"evaluations/\"+notebook_name+\".tsv\",index = False,sep='\\t',line_terminator='\\r\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New images, index and different weights for clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from elasticsearch import Elasticsearch\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "\n",
    "# #PARSE ARGUMENTS\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-i\", \"--input-dir\")\n",
    "# parser.add_argument(\"-o\", \"--output-dir\")\n",
    "# args = parser.parse_args()\n",
    "# args = vars(args)\n",
    "\n",
    "# #HANDLE INPUT\n",
    "# input_dir = args['input_dir']\n",
    "# output_dir = args['output_dir']\n",
    "\n",
    "es = Elasticsearch(hosts=\"localhost\")\n",
    "\n",
    "while not es.ping():\n",
    "    sleep(10)\n",
    "    print(\"WAITING...\")\n",
    "    es = Elasticsearch(hosts=\"localhost\", timeout=300)\n",
    "print(\"done waiting\")\n",
    "\n",
    "###############\n",
    "# make dictionary with all topics\n",
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('topics_selected.xml')\n",
    "# tree = ET.parse('topics_selected.xml')\n",
    "topics = tree.findall('topic')\n",
    "\n",
    "# Dictionary with all 50 topics\n",
    "topicsDic = {}\n",
    "\n",
    "for topic in topics:\n",
    "    title = topic.find('title').text\n",
    "    number = topic.find('number').text\n",
    "    topicsDic[number] = title\n",
    "\n",
    "num_results = 10\n",
    "\n",
    "## third run: sentiment+OCR+ImageClustering###\n",
    "def search_refined_OCR_Clustering_prototype(query, num_results):\n",
    "    body_positive = {\n",
    "        \"from\":0,\n",
    "        \"size\":num_results,\n",
    "        \"query\": {\n",
    "        \"function_score\": {\n",
    "        \"query\": {\n",
    "            \"bool\":{\n",
    "                \"should\":[\n",
    "                    {\"match\": { \"document_text\":{\"query\":query}}},\n",
    "                    {\"match\": {\"ocr_text\":{\"query\":query, \"boost\":5}}}\n",
    "                ],\n",
    "\n",
    "                \"filter\":[\n",
    "                    {\"range\": {\"sentiment\": {\"gt\": 0}}}\n",
    "                ]\n",
    "            }   \n",
    "        },\n",
    "        #\"boost\": \"5\", \n",
    "        \"functions\": [\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"0\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"1\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"2\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"3\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"4\" } },\"weight\": 4.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"5\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"6\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"7\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"8\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"9\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"10\" } },\"weight\": 2.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"11\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"12\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"13\" } },\"weight\": 2.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"999\" } },\"weight\": 0.0}\n",
    "        ],      \n",
    "        \"max_boost\": 5.0,\n",
    "        \"score_mode\": \"max\",\n",
    "        \"boost_mode\": \"multiply\",\n",
    "        \"min_score\": 0.0\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    res_positive = es.search(index=\"final_boromir_index\", body=body_positive)\n",
    "\n",
    "    body_negative = {\n",
    "        \"from\":0,\n",
    "        \"size\":num_results,\n",
    "        \"query\": {\n",
    "        \"function_score\": {\n",
    "        \"query\": {\n",
    "            \"bool\":{\n",
    "                \"should\":[\n",
    "                    {\"match\": { \"document_text\":{\"query\":query}}},\n",
    "                    {\"match\": {\"ocr_text\":{\"query\":query, \"boost\":5}}}\n",
    "                ],\n",
    "\n",
    "                \"filter\":[\n",
    "                    {\"range\": {\"sentiment\": {\"lt\": 0}}}\n",
    "                ]\n",
    "            }   \n",
    "        },\n",
    "        #\"boost\": \"5\", \n",
    "        \"functions\": [\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"0\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"1\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"2\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"3\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"4\" } },\"weight\": 4.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"5\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"6\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"7\" } },\"weight\": 3.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"8\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"9\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"10\" } },\"weight\": 2.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"11\" } },\"weight\": 5.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"12\" } },\"weight\": 1.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"13\" } },\"weight\": 2.0},\n",
    "            {\"filter\": { \"match\": { \"cluster_when_14_clusters_in_10dim\": \"999\" } },\"weight\": 0.0}\n",
    "        ],      \n",
    "        \"max_boost\": 5.0,\n",
    "        \"score_mode\": \"max\",\n",
    "        \"boost_mode\": \"multiply\",\n",
    "        \"min_score\": 0.0\n",
    "        }\n",
    "        }\n",
    "    }\n",
    "    res_negative = es.search(index=\"final_boromir_index\", body=body_negative)\n",
    "\n",
    "    # get ID's from retrieved documents\n",
    "    result_positive_ids = []\n",
    "    results_positive = res_positive.get('hits').get('hits')\n",
    "\n",
    "    for doc in results_positive:\n",
    "        id = doc.get('_id')\n",
    "        result_positive_ids.append(id)\n",
    "\n",
    "    result_negative_ids = []\n",
    "    results_negative = res_negative.get('hits').get('hits')\n",
    "\n",
    "    for doc in results_negative:\n",
    "        id = doc.get('_id')\n",
    "        result_negative_ids.append(id)\n",
    "\n",
    "    return result_positive_ids, result_negative_ids\n",
    "\n",
    "resultList = []\n",
    "for topic in topicsDic:\n",
    "    query = topicsDic.get(topic)\n",
    "    result_ids_pro, result_ids_con = search_refined_OCR_Clustering_prototype(query, num_results)\n",
    "    for each in result_ids_pro:\n",
    "        resultList.append([topic, \"PRO\", each, 0, 0.0, \"Boromir3\"])\n",
    "    for each in result_ids_con:\n",
    "        resultList.append([topic, \"CON\", each, 0, 0.0, \"Boromir3\"])\n",
    "\n",
    "resultdf = pd.DataFrame(resultList, columns = ['topicID','stance','pageID','rank','score','Method'])\n",
    "with open(f'run.txt', 'a+') as f:\n",
    "    resultdf[['topicID','stance','pageID','rank','score','Method']].to_csv(f, sep=' ', header=False, index=False)\n",
    "\n",
    "print(resultdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import define\n",
    "\n",
    "path_to_images = define.imagePath()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thilo\\AppData\\Local\\Temp/ipykernel_3036/1198321886.py:87: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  res_positive = es.search(index=\"final_boromir_index\", body=body_positive)\n",
      "C:\\Users\\thilo\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\elasticsearch\\connection\\base.py:200: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.15/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n",
      "C:\\Users\\thilo\\AppData\\Local\\Temp/ipykernel_3036/1198321886.py:131: DeprecationWarning: The 'body' parameter is deprecated for the 'search' API and will be removed in a future version. Instead use API parameters directly. See https://github.com/elastic/elasticsearch-py/issues/1698 for more information\n",
      "  res_negative = es.search(index=\"final_boromir_index\", body=body_negative)\n"
     ]
    }
   ],
   "source": [
    "resultHTML = 'newData6.html'\n",
    "tsv_name = 'newData6'\n",
    "\n",
    "htmlEval = '<!DOCTYPE html> <html>     <head>         <meta charset=\"UTF-8\" name=\"viewport\" content=\"width=device-width, initial-scale=1, maximum-scale=1\">         <title>Evaluation</title> <link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css\" integrity=\"sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm\" crossorigin=\"anonymous\">   <link rel=\"stylesheet\" href=\"myCss.css\">      <script src=\"https://code.jquery.com/jquery-3.2.1.slim.min.js\" integrity=\"sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN\" crossorigin=\"anonymous\"></script>   <script src=\"https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js\" integrity=\"sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q\" crossorigin=\"anonymous\"></script>    <script src=\"https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js\" integrity=\"sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl\" crossorigin=\"anonymous\"></script> '\n",
    "htmlEval = htmlEval + '<script language=\"Javascript\" > \\n const dataList = [] \\n function addDataToList(query, argpro, argcon, pos, neg) {  var { value } = document.getElementById(\"user_name\").elements[\"user\"]   \\n  if(value == \"\"){ alert (\"Please fill in User!\")} \\n  else{ \\n dataList.push(query)    \\n var { value } = argpro     \\n dataList.push(value)    \\n var { value } = argcon     \\n dataList.push(value)     \\n var { value } = pos   \\n dataList.push(value)     \\n var { value } = neg  \\n dataList.push(value)    \\n  var { value } = document.getElementById(\"user_name\").elements[\"user\"]   \\n  dataList.push(value)       \\n dataList.push(\" \\\\n\") \\n alert(\"Inhalt von dataList: \"+dataList)  } }  \\n function downloadFile() { \\n const textFile = btoa(\"query \\\\t Argumentative images pro \\\\t Argumentative images con \\\\t correct positives \\\\t correct negatives \\\\t user_name \\\\n \\\\t\" + dataList.join(\"\\\\t\")) \\n const saveElement = document.createElement(\"a\") \\n saveElement.href = `data:text/plain;base64,${textFile}` \\n var { value } = document.getElementById(\"user_name\").elements[\"user\"]   \\n  saveElement.download = \"' + tsv_name + '\"+value+\".tsv\" \\n document.body.appendChild(saveElement) \\n saveElement.click() \\n document.body.removeChild(saveElement)  } \\n </script>'\n",
    "htmlEval = htmlEval + '</head> <body>   \\n  <div class=\"form-group mb-5\">   \\n  <input id=\"download_btn\" type=\"submit\" class=\"btn btn-primary\" onClick=\"downloadFile(); \" value=\"Exportieren\" />    \\n  </div>  \\n  <div class=\"container-out\"> \\n  <form name=\"username\" action=\"\" method=\"post\" id=\"user_name\">   \\n  <div class=\"form-group row\">    \\n  <label for=\"username\" class=\"col-sm-2 col-form-label\">User: </label>    \\n  <div class=\"col-sm-10\"> \\n  <select multiple class=\"form-control\" name=\"user\">  \\n  <option>Gregor</option> \\n  <option>Miriam</option> \\n  <option>Shirin</option> \\n  <option>Thilo</option>  \\n  </select></div> \\n  </div>  \\n  </form>'\n",
    "num_results = 10\n",
    "\n",
    "\n",
    "queryListdf = pd.DataFrame(columns = ['topic', 'stance', 'id'])\n",
    "for tid in topicsDic:\n",
    "    pre_query = topicsDic.get(tid)\n",
    "    query = query_preprocessing(pre_query)\n",
    "\n",
    "    result_ids_pro, result_ids_con =  search_refined_OCR_Clustering_prototype(query, num_results)\n",
    "    src_pro = []\n",
    "    src_con = []\n",
    "\n",
    "    for ids in result_ids_pro:\n",
    "        src_pro.append(\"images/\"  + ids[0:3] + \"/\" + ids + \"/image.png\")\n",
    "    for ids in result_ids_con:\n",
    "        src_con.append(\"images/\"  + ids[0:3] + \"/\" + ids + \"/image.png\")\n",
    "\n",
    "    link_pro = []\n",
    "    link_con = []\n",
    "    #open only directory to get link\n",
    "    for ids in result_ids_pro:\n",
    "        with open(path_to_images + \"/images/\" + ids[0:3] + \"/\" + ids + \"/pages/\" + listdir(path_to_images + \"/images/\" + ids[0:3] + \"/\" + ids + \"/pages\")[0] + \"/page-url.txt\") as f:\n",
    "            this_link = f.read()\n",
    "            link_pro.append(this_link)\n",
    "\n",
    "    for ids in result_ids_con:\n",
    "        with open(path_to_images + \"/images/\" + ids[0:3] + \"/\" + ids + \"/pages/\" + listdir(path_to_images + \"/images/\" + ids[0:3] + \"/\" + ids + \"/pages\")[0] + \"/page-url.txt\") as f:\n",
    "            this_link = f.read()\n",
    "            link_con.append(this_link)\n",
    "\n",
    "    #data for HTML processing\n",
    "    # queryList.append(query)\n",
    "    evaluation = open(\"evaluation+link.html\").read().format(query=pre_query, \n",
    "                                    firstpro = src_pro[0],\n",
    "                                    secondpro = src_pro[1],\n",
    "                                    thirdpro = src_pro[2],\n",
    "                                    fourthpro = src_pro[3],\n",
    "                                    fifthpro = src_pro[4],\n",
    "                                    sixthpro = src_pro[5], \n",
    "                                    seventhpro = src_pro[6], \n",
    "                                    eighthpro = src_pro[7], \n",
    "                                    ninthpro = src_pro[8], \n",
    "                                    tenthpro = src_pro[9], \n",
    "                                    firstcon = src_con[0], \n",
    "                                    secondcon = src_con[1], \n",
    "                                    thirdcon = src_con[2], \n",
    "                                    fourthcon = src_con[3], \n",
    "                                    fifthcon = src_con[4], \n",
    "                                    sixthcon = src_con[5],\n",
    "                                    seventhcon = src_con[6],\n",
    "                                    eighthcon = src_con[7], \n",
    "                                    ninthcon = src_con[8], \n",
    "                                    tenthcon = src_con[9], \n",
    "                                    onepro = link_pro[0], \n",
    "                                    twopro = link_pro[1], \n",
    "                                    threepro = link_pro[2], \n",
    "                                    fourpro = link_pro[3], \n",
    "                                    fivepro = link_pro[4], \n",
    "                                    sixpro = link_pro[5], \n",
    "                                    sevenpro = link_pro[6], \n",
    "                                    eightpro = link_pro[7], \n",
    "                                    ninepro = link_pro[8], \n",
    "                                    tenpro = link_pro[9],\n",
    "                                    onecon = link_con[0],\n",
    "                                    twocon = link_con[1], \n",
    "                                    threecon = link_con[2], \n",
    "                                    fourcon = link_con[3], \n",
    "                                    fivecon = link_con[4], \n",
    "                                    sixcon = link_con[5], \n",
    "                                    sevencon = link_con[6], \n",
    "                                    eightcon = link_con[7], \n",
    "                                    ninecon = link_con[8], \n",
    "                                    tencon = link_con[9])\n",
    "    #print(topic)\n",
    "    # for id in result_ids_pro:\n",
    "    #     # print(id)\n",
    "    #     queryListdf = queryListdf.append({\"topic\": query, \"stance\": \"pro\", \"id\": (\"/images/\"  + id[0:3] + \"/\" + id + \"/pages/\")}, ignore_index=True)\n",
    "    # for id in result_ids_con:\n",
    "    #     queryListdf = queryListdf.append({\"topic\": query, \"stance\": \"con\", \"id\": (\"/images/\"  + id[0:3] + \"/\" + id + \"/pages/\")}, ignore_index=True)\n",
    "\n",
    "    htmlEval = htmlEval + evaluation\n",
    "\n",
    "    \n",
    "htmlEval = htmlEval + '</body> </html>'\n",
    "file = open(resultHTML, 'w')\n",
    "file.write(htmlEval)\n",
    "file.close()\n",
    "    \n",
    "##debugging/check\n",
    "#print(queryListdf)\n",
    "#queryListdf.to_csv(\"evaluations/\"+notebook_name+\".tsv\",index = False,sep='\\t',line_terminator='\\r\\n')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "674a4eb853ef3b8ee2c8318a5f62f960f9c782f62ac23f0329d0e827277c513e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
